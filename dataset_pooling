# -*- coding: utf-8 -*-
"""
Created on Wed Feb  1 09:51:50 2023

@author: wiesbrock
"""
# -*- coding: utf-8 -*-
"""
Created on Thu Jan 26 14:58:58 2023

@author: wiesbrock
"""



from IPython import get_ipython
#get_ipython().magic('reset -sf')

import numpy as np
import glob
import matplotlib.pyplot as plt
import pandas as pd
import os
import scipy.stats as stats
import seaborn as sns




path=r'C:\Users\wiesbrock\Desktop\time_series_AmhDHT_adult\\'
folder=path+'*.xlsx'

os.chdir(path)


folder_list=glob.glob(folder)

    


def crosscorr(datax, datay, lag=0):
    """ Lag-N cross correlation. 
    Parameters
    ----------
    lag : int, default 0
    datax, datay : pandas.Series objects of equal length
    Returns
    ----------
    crosscorr : float
    """
    return datax.corr(datay.shift(lag))

all_cross_corr=list()
all_index=list()


for m in range(len(folder_list)):

    #files=str(folder_list[m])+'\\results\\manual\\time_series.xlsx'
    #meta=str(folder_list[m])+'\\Intervals.txt'
    
    files=str(folder_list[m])




    df=pd.read_excel(files,sheet_name=None,engine='openpyxl')

    
    a=df['detrended']
   
    
    
    
    header=list(a.columns.values)
    v=0
    peaks_all=np.zeros((len(header),1))
    j=0
    
    
    d=np.empty((len(header),len(a)))
    
    
    
    for i in header:
        
        zscore=stats.zscore(a[i])
        peaks=np.where(zscore>=2.)
        peaks=peaks[0]
        peak_diff=np.diff(peaks)
        peak_diff=peak_diff
        number_of_peaks=len(peak_diff[peak_diff>=15])
        peaks_all[v]=number_of_peaks+1
        #plt.axis('off')
        binary=np.zeros((len(zscore),1))
        binary[peaks]=1
        binary=np.reshape(binary,(len(a),))
        d[j]=binary
        j=j+1
        
        v=v+1
        thr=0
        
    names=list(a.columns)
    corr_matrx=np.zeros((len(names),len(names)))
    index_max_corr=np.zeros((len(names),len(names)))
    b=np.zeros((80,1))
    for i in range(len(names)):
        for k in range(len(names)):
            trace_1=(d[i])
            trace_2=(d[k])
            trace_1=pd.DataFrame(trace_1)
            trace_2=pd.DataFrame(trace_2)
            trace_1=trace_1.squeeze()
            trace_2=trace_2.squeeze()
            for n in range(80):
                p=n-40
                b[n]=crosscorr(trace_1,trace_2, lag=p)
                corr_matrx[i,k]=np.nanmax(b)
                index_max_corr[i,k]=np.where(b==np.nanmax(b))[0][0]
    index_max_corr=np.abs(index_max_corr-40)
    all_cross_corr.append(np.concatenate(corr_matrx,axis=0))
    all_index.append(np.concatenate(index_max_corr,axis=0))

all_cross_corr=np.concatenate(all_cross_corr)
all_index=np.concatenate(all_index)
all_index=all_index[all_cross_corr<.99]
all_cross_corr=all_cross_corr[all_cross_corr<.99]
r_square=all_cross_corr**2




plt.figure(dpi=300)
hist,edges=np.histogram(r_square, bins=10)

plt.plot(edges[:-1],hist/2, 'k-')

plt.ylabel('Count')
plt.xlabel('r_square')
sns.despine()

plt.savefig('R_square histogram.svg')


plt.figure(dpi=300)
hist,edges=np.histogram(all_index, bins=10)

plt.plot(edges[:-1],hist/2, 'k-')

plt.ylabel('Count')
plt.xlabel('Lag')
sns.despine()

plt.savefig('Lag histogram.svg')



from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
X=list(zip(r_square[all_cross_corr>0.5],all_index[all_cross_corr>0.5]))

X=pd.DataFrame(data=X)
scaler=StandardScaler()
X=scaler.fit_transform(X)
kmeans = KMeans(n_clusters=3)
kmeans.fit(X)
y_kmeans = kmeans.predict(X)

plt.figure(dpi=300)
plt.scatter(all_index[all_cross_corr>0.5],r_square[all_cross_corr>0.5], marker='o',c=y_kmeans)
plt.xlabel('Lag')
plt.ylabel('r_square')
sns.despine()

plt.savefig('cluster_scatter.svg')

percent=len(r_square[r_square>0.5])
percent=percent/len(r_square)
percent=percent*100

print('Amount of cell pairs with a r_squared higher then 0.5 '+str(percent)+' %')

percent=len(all_cross_corr[all_cross_corr>0.5])
percent=percent/len(all_cross_corr)
percent=percent*100

print('Amount of cell pairs with a cross corr higher then 0.5 '+str(percent)+' %')

distortions = []
K = range(1,10)
for k in K:
    kmeanModel = KMeans(n_clusters=k)
    kmeanModel.fit(X)
    distortions.append(kmeanModel.inertia_)

plt.figure(figsize=(16,8),dpi=300)
plt.plot(K, distortions, 'bx-')
plt.xlabel('k')
plt.ylabel('Distortion')
plt.title('The Elbow Method showing the optimal k')
plt.savefig('elbow.svg')
plt.show()

